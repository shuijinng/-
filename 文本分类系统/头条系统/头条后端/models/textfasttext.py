# train_fasttext.py - å¸¦è¿›åº¦æ¡ + æ–‡ä»¶éªŒè¯ + æ¨¡å‹ä¿å­˜
import os
from tqdm import tqdm
import fasttext

# ==================== è·¯å¾„é…ç½® ====================
# ä½ æŒ‡å®šçš„è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
TEMP_FILE = r"D:\111huiyu\train_fasttext.txt"

# æ¨¡å‹ä¿å­˜è·¯å¾„
MODEL_DIR = r"D:\111huiyu\model"
MODEL_PATH = os.path.join(MODEL_DIR, "fasttext_model.bin")

# åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs(MODEL_DIR, exist_ok=True)

# ==================== æ£€æŸ¥è®­ç»ƒæ–‡ä»¶ ====================
print(f"ğŸ” æ­£åœ¨æ£€æŸ¥è®­ç»ƒæ–‡ä»¶: {TEMP_FILE}")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(TEMP_FILE):
    raise FileNotFoundError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\nğŸ‘‰ {TEMP_FILE}")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
file_size = os.path.getsize(TEMP_FILE)
if file_size == 0:
    raise ValueError(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸ºç©ºï¼è¯·é‡æ–°ç”Ÿæˆæ•°æ®ã€‚\nğŸ‘‰ {TEMP_FILE}")

print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size / 1024:.2f} KB")

# è¯»å–å‰3è¡Œåšæ ¼å¼æ£€æŸ¥
with open(TEMP_FILE, 'r', encoding='utf-8') as f:
    sample_lines = [next(f).strip() for _ in range(3)]

print("ğŸ“„ æ–‡ä»¶å‰3è¡Œç¤ºä¾‹:")
for i, line in enumerate(sample_lines, 1):
    print(f"   {i}: {line}")

# ç®€å•éªŒè¯æ ¼å¼
for line in sample_lines:
    if not line.startswith("__label__"):
        print("âš ï¸  è­¦å‘Šï¼šè¡Œä¸ä»¥ '__label__' å¼€å¤´ï¼ŒfastText å¯èƒ½æ— æ³•è¯†åˆ«ï¼")
        break

# ==================== å¼€å§‹è®­ç»ƒï¼ˆå¸¦è¿›åº¦æ¡ï¼‰====================
print("\nğŸš€ å¼€å§‹è®­ç»ƒ fastText æ¨¡å‹...")

try:
    model = fasttext.train_supervised(
        input=TEMP_FILE,
        epoch=25,           # è®­ç»ƒè½®æ•°
        lr=1.0,             # å­¦ä¹ ç‡
        wordNgrams=2,       # äºŒå…ƒè¯­æ³•ï¼Œæå‡æ•ˆæœ
        dim=100,            # è¯å‘é‡ç»´åº¦
        minCount=1,         # æœ€å°è¯é¢‘
        verbose=2,          # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ï¼ˆç›¸å½“äºè¿›åº¦ï¼‰
        loss="softmax"      # æŸå¤±å‡½æ•°
    )

    # ä¿å­˜æ¨¡å‹
    model.save_model(MODEL_PATH)
    print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å·²ä¿å­˜åˆ°ï¼š\nğŸ‘‰ {MODEL_PATH}")

    # å¯é€‰ï¼šæ‰“å°ä¸€äº›æ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹ç»´åº¦: {model.f.dim}")
    print(f"ğŸ“š è¯æ±‡é‡: {model.f.words}")
    print(f"ğŸ·ï¸  æ ‡ç­¾æ•°: {model.f.labels}")

except Exception as e:
    print(f"âŒ è®­ç»ƒå¤±è´¥ï¼é”™è¯¯ä¿¡æ¯ï¼š{e}")
    raise

# ==================== ç®€å•æµ‹è¯• ====================
print("\nğŸ§ª æ¨¡å‹æµ‹è¯•ï¼š")
test_texts = [
    "ä¸­åå¥³å­å­¦é™¢ æ‹›æ”¶ ç”·ç”Ÿ",
    "æ‰‹æœº é’±åŒ… ç§‘æŠ€ åˆ›æ–°",
    "ææ°¸æ³¢ è°¢æèŠ³ æ—ä¸¹ ç¾½æ¯›çƒ"
]

for text in test_texts:
    label_pred, prob = model.predict(text.replace(" ", ""))  # åŸå§‹æ¨¡å‹æ¥å—æœªåˆ†è¯æ–‡æœ¬ï¼ˆä½†ä½ è®­ç»ƒæ—¶æ˜¯åˆ†è¯çš„ï¼‰
    print(f"  '{text}' â†’ é¢„æµ‹: {label_pred[0]} (ç½®ä¿¡åº¦: {prob[0]:.4f})")